{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<splinter.driver.webdriver.WebDriverElement object at 0x0000027A80EFAF88>\n",
      "No, it wasn't found... We need to improve our SEO techniques\n"
     ]
    }
   ],
   "source": [
    "with Browser(\"chrome\") as browser:\n",
    "    # Visit URL\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "    browser.fill('search', 'splinter - python acceptance testing for web applications')\n",
    "    # Find and click the 'search' button\n",
    "    button = browser.find_by_css('input.search_submit')\n",
    "    print(button[0])\n",
    "    # Interact with elements\n",
    "    button[0].click()\n",
    "    if browser.is_text_present('There are no items matching these criteria.'):\n",
    "        print(\"Yes, the official website was found!\")\n",
    "    else:\n",
    "        print(\"No, it wasn't found... We need to improve our SEO techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "#```python\n",
    "# Example:\n",
    "news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Alabama High School Student Names NASA's Mars Helicopter\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Browser(\"chrome\") as browser:\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "    html = bs(browser.html, 'html.parser')\n",
    "    \n",
    "    body = html.body\n",
    "#     body.strippedtext\n",
    "#     print(body.a)\n",
    "\n",
    "    print(body.find_all(\"div\", class_='content_title')[1].getText())\n",
    "#     titles = body.find_all(\"div\", class_='content_title')\n",
    "#     first = titles[1].getText()\n",
    "#     print(first)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA17838_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image and \n",
    "#assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "# * Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "\n",
    "# * Make sure to save a complete url string for this image.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "\n",
    "base_url = \"https://www.jpl.nasa.gov\"\n",
    "search_url = '/spaceimages/?search=&category=Mars'\n",
    "url = base_url + search_url\n",
    "featured_image_url = None\n",
    "with Browser(\"chrome\") as browser:\n",
    "    browser.visit(url)\n",
    "    image = browser.find_by_id('full_image')[0]\n",
    "    featured_image_url = base_url + image['data-fancybox-href']\n",
    "    print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and \n",
    "#scrape the latest Mars weather tweet from the page. Save the tweet text for the weather \n",
    "#report as a variable called `mars_weather`.\n",
    "#Note: Be sure you are not signed in to twitter, or scraping may become more difficult.**\n",
    "import time\n",
    "with Browser(\"chrome\") as browser:\n",
    "    url_weather = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    browser.visit(url_weather) \n",
    "    html_weather = browser.html\n",
    "    time.sleep(5)\n",
    "    soup = bs(html_weather, \"html.parser\")\n",
    "    main = soup.main\n",
    "    temp = main.find_all('section', attrs={\"aria-labelledby\": \"accessible-list-0\"})\n",
    "    elements = soup.find_all(\"section\", class_=\"css-1dbjc4n\")\n",
    "    for e in elements:\n",
    "        print(e)\n",
    "    print(temp.text)\n",
    "    print(temp[0])\n",
    "#     url= \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "# with Browser(\"chrome\") as browser:\n",
    "\n",
    "#     browser.visit(url) \n",
    "#     html = browser.html\n",
    "#     soup = bs(html, 'html.parser')\n",
    "#     xpath = \"//div[@class='description']//a[@class='itemLink product-item']/h3\"\n",
    "#     results = browser.find_by_xpath(xpath)\n",
    "#     hemisphere_image_urls = []\n",
    "#     for i in range(4):\n",
    "#         html = browser.html\n",
    "#         soup = bs(html, 'html.parser')\n",
    "#         # find the new Splinter elements\n",
    "#         results = browser.find_by_xpath(xpath)\n",
    "#         # save name of the hemisphere\n",
    "#         header = results[i].html\n",
    "#         # go to  hemisphere details page \n",
    "#         details_link = results[i]\n",
    "#         details_link.click()\n",
    "\n",
    "#         html = browser.html\n",
    "#         soup = bs(html, 'html.parser')\n",
    "#         # Save the image url\n",
    "#         hemisphere_image_urls.append({\"title\": header, \"image_url\": soup.find(\"div\", class_=\"downloads\").a[\"href\"]})\n",
    "#         # Go back to the original page\n",
    "#         browser.back()\n",
    "\n",
    "#     print(hemisphere_image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table \n",
    "#containing facts about the planet including Diameter, Mass, etc.\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "data = pd.read_html(url)\n",
    "df = data[0]\n",
    "\n",
    "df.columns = ['Description', 'Value']\n",
    "df.set_index('Description', inplace=True)\n",
    "mars_html_table = df.to_html()\n",
    "print(df)\n",
    "\n",
    "\n",
    "#Use Pandas to convert the data to a HTML table string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars)\n",
    "# to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "# * You will need to click each of the links to the hemispheres in order to find \n",
    "# the image url to the full resolution image.\n",
    "\n",
    "# * Save both the image url string for the full resolution hemisphere image, and \n",
    "# the Hemisphere title containing the hemisphere name. Use a Python dictionary to store \n",
    "#the data using the keys `img_url` and `title`.\n",
    "\n",
    "# * Append the dictionary with the image url string and the hemisphere title to a list.\n",
    "# This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]\n",
    "# ```\n",
    "\n",
    "url= \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "with Browser(\"chrome\") as browser:\n",
    "\n",
    "    browser.visit(url) \n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    xpath = \"//div[@class='description']//a[@class='itemLink product-item']/h3\"\n",
    "    results = browser.find_by_xpath(xpath)\n",
    "    hemisphere_image_urls = []\n",
    "    for i in range(4):\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        # find the new Splinter elements\n",
    "        results = browser.find_by_xpath(xpath)\n",
    "        # save name of the hemisphere\n",
    "        header = results[i].html\n",
    "        # go to  hemisphere details page \n",
    "        details_link = results[i]\n",
    "        details_link.click()\n",
    "\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        # Save the image url\n",
    "        hemisphere_image_urls.append({\"title\": header, \"image_url\": soup.find(\"div\", class_=\"downloads\").a[\"href\"]})\n",
    "        # Go back to the original page\n",
    "        browser.back()\n",
    "\n",
    "    print(hemisphere_image_urls)\n",
    "    #to make it prettier\n",
    "    for i in hemisphere_image_urls: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
